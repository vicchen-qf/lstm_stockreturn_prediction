# -*- coding: utf-8 -*-
"""lstm_return_2327.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ZbrIm0HSZlEvio4Eph0vzorr2JhTyrGI
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
from google.colab import files
from keras.models import Sequential,Model
from keras.layers import Dense, Dropout, Activation, Flatten, LSTM, TimeDistributed, RepeatVector,Input
from keras.optimizers import Adam
from keras.callbacks import EarlyStopping, ModelCheckpoint
import matplotlib.pyplot as plt
from keras.utils import to_categorical
import keras
# %matplotlib inline

from google.colab import drive
drive.mount('/content/drive')

data_train = pd.read_csv('/content/drive/My Drive/實習/train_2327.csv')
data_test = pd.read_csv('/content/drive/My Drive/實習/test_2327.csv')

data_train

#技術指標
#Moving Average  
def MA(df, n):  
    MA = df.rolling(n).mean()
    return MA

#均價線
def AVL(df):#, tick_N):
    AVL =  pd.DataFrame(data = np.zeros((len(df), 1)), index = df.index, columns = ['AVL'])  
    AVL['AVL'] = np.cumsum(df['DealPrice']*df['DealQty']) / np.cumsum(df['DealQty'])
    AVL['%AVL'] = df['mid1'] / AVL['AVL'] - 1
    return AVL

#布林通道
def BBANDS(df, n, multiple, tick_N):  
    MA = df.rolling(n).mean()
    #%change
    MA_ = MA / MA.shift(tick_N) -1
    MSD = df.rolling(n).std()
    ub1 =  MA + multiple * MSD
    #%change
    ub1_ = ub1 / ub1.shift(tick_N) -1
    uB1 = pd.DataFrame(ub1_, index = df.index, columns = df.columns)  
    lb1 =  MA - multiple * MSD
    #%change
    lb1_ = lb1 / lb1.shift(tick_N) -1
    lB1 = pd.DataFrame(lb1_, index = df.index, columns = df.columns)  
    b2 = (df - MA + multiple * MSD) / (2 * multiple * MSD)  
    B2 = pd.DataFrame(b2, index = df.index, columns = df.columns)  
    BBAND = pd.concat([uB1, lB1, B2], keys = ['UpperBand', 'LowerBand', '%B'], axis = 1)
    BBAND.columns = ['UpperBand', 'LowerBand', '%B']
    return BBAND

#MACD, MACD Signal and MACD difference  
def MACD(df, n_fast, n_slow, C_price_name='mid1'):   
    EMAfast = df[C_price_name].ewm(span = n_fast, min_periods = n_slow - 1).mean() 
    EMAslow = df[C_price_name].ewm(span = n_slow, min_periods = n_slow - 1).mean() 
    #短EMA-長EMA
    MACD = pd.Series(EMAfast - EMAslow, name = 'MACD_' + str(n_fast) + '_' + str(n_slow))  
    MACDsign = pd.Series(MACD.ewm(span = 9, min_periods = 8).mean(), name = 'MACDsign_' + str(n_fast) + '_' + str(n_slow))  
    MACDdiff = pd.Series(MACD - MACDsign, name = 'MACDdiff_' + str(n_fast) + '_' + str(n_slow))  
    MACD = pd.concat([MACD, MACDsign, MACDdiff], axis = 1)
    return MACD

#generate features
def AlphaGenerate_Tick(original_data,bb=False,avl=False,spread=False,macd=False,price_diff=False,
                       price_mean=False,qty_mean=False,acc_diff=False,dt1p=False,dt5p=False,dt10p=False,
                      cross1=False,cross5=False,cross10=False,spread_pq=False,price_diff_pq=False,
                      spread_pct_pq=False,pq_mean=False,acc_diff_pq=False,dt1_pq=False,dt5_pq=False,dt10_pq=False,
                      ma=False,dt1q=False,dt5q=False,dt10q=False):
    ############################################################################################################################
    #需要預先處裡的東西放這邊
    #build Date column
    #original_data['Date'] = pd.to_datetime(original_data['TxTime'])
    #original_data['Date'] = [str(x)[0:10] for x in original_data['Date']]
    #df to save X
    X = pd.DataFrame()
    #copy
    data=original_data.copy()
    #mid
    data['mid1'] = (data['Ask1'] + data['Bid1']) / 2
    data['mid2'] = (data['Ask2'] + data['Bid2']) / 2
    data['mid3'] = (data['Ask3'] + data['Bid3']) / 2
    data['mid4'] = (data['Ask4'] + data['Bid4']) / 2
    data['mid5'] = (data['Ask5'] + data['Bid5']) / 2
    #some index's ask1 = 0, we change that mid1 to bid1
    idx = data[data['Ask1'] == 0].index
    for i in idx:
        data['mid1'].iloc[i] = data['Bid1'].iloc[i]
    #委買委賣比，判斷買賣邊力道
    data['Ask1_value'] = data['AskQty1']/(data['BidQty1']+data['AskQty1'])
    data['Ask2_value'] = data['AskQty2']/(data['BidQty2']+data['AskQty2'])
    data['Ask3_value'] = data['AskQty3']/(data['BidQty3']+data['AskQty3'])
    data['Ask4_value'] = data['AskQty4']/(data['BidQty4']+data['AskQty4'])
    data['Ask5_value'] = data['AskQty5']/(data['BidQty5']+data['AskQty5'])
    data['Bid1_value'] = data['BidQty1']/(data['BidQty1']+data['AskQty1'])
    data['Bid2_value'] = data['BidQty2']/(data['BidQty2']+data['AskQty2'])
    data['Bid3_value'] = data['BidQty3']/(data['BidQty3']+data['AskQty3'])
    data['Bid4_value'] = data['BidQty4']/(data['BidQty4']+data['AskQty4'])
    data['Bid5_value'] = data['BidQty5']/(data['BidQty5']+data['AskQty5'])
    #ask and askqty <-> bid and bidqty if one side = 0
    data['Ask1'][data['Ask1']==0]=data['Bid1']
    data['Ask2'][data['Ask2']==0]=data['Bid2']
    data['Ask3'][data['Ask3']==0]=data['Bid3']
    data['Ask4'][data['Ask4']==0]=data['Bid4']
    data['Ask5'][data['Ask5']==0]=data['Bid5']
    data['AskQty1'][data['AskQty1']==0]=data['BidQty1']
    data['AskQty2'][data['AskQty2']==0]=data['BidQty2']
    data['AskQty3'][data['AskQty3']==0]=data['BidQty3']
    data['AskQty4'][data['AskQty4']==0]=data['BidQty4']
    data['AskQty5'][data['AskQty5']==0]=data['BidQty5']
    data['Bid1'][data['Bid1']==0]=data['Ask1']
    data['Bid2'][data['Bid2']==0]=data['Ask2']
    data['Bid3'][data['Bid3']==0]=data['Ask3']
    data['Bid4'][data['Bid4']==0]=data['Ask4']
    data['Bid5'][data['Bid5']==0]=data['Ask5']
    data['BidQty1'][data['BidQty1']==0]=data['AskQty1']
    data['BidQty2'][data['BidQty2']==0]=data['AskQty2']
    data['BidQty3'][data['BidQty3']==0]=data['AskQty3']
    data['BidQty4'][data['BidQty4']==0]=data['AskQty4']
    data['BidQty5'][data['BidQty5']==0]=data['AskQty5']
    #df to save
    #df_date = pd.DataFrame()
    #date_idx = data['Date'].unique()
    #value(price*quantity)
    #data['Ask1_value'] = data['Ask1']*data['AskQty1']
    #data['Ask2_value'] = data['Ask2']*data['AskQty2']
    #data['Ask3_value'] = data['Ask3']*data['AskQty3']
    #data['Ask4_value'] = data['Ask4']*data['AskQty4']
    #data['Ask5_value'] = data['Ask5']*data['AskQty5']
    #data['Bid1_value'] = data['Bid1']*data['BidQty1']
    #data['Bid2_value'] = data['Bid2']*data['BidQty2']
    #data['Bid3_value'] = data['Bid3']*data['BidQty3']
    #data['Bid4_value'] = data['Bid4']*data['BidQty4']
    #data['Bid5_value'] = data['Bid5']*data['BidQty5']
    ############################################################################################################################
    #因子放這邊
    #不用考慮換日的因子 
    #MA
    if ma == True:
        X['MA50_ask1']=MA(data['Ask1_value'], 50)-data['Ask1_value']
        X['MA50_ask2']=MA(data['Ask2_value'], 50)-data['Ask2_value']
        X['MA50_ask3']=MA(data['Ask3_value'], 50)-data['Ask3_value']
        X['MA50_ask4']=MA(data['Ask4_value'], 50)-data['Ask4_value']
        X['MA50_ask5']=MA(data['Ask5_value'], 50)-data['Ask5_value']
        X['MA50_bid1']=MA(data['Bid1_value'], 50)-data['Bid1_value']
        X['MA50_bid2']=MA(data['Bid2_value'], 50)-data['Bid2_value']
        X['MA50_bid3']=MA(data['Bid3_value'], 50)-data['Bid3_value']
        X['MA50_bid4']=MA(data['Bid4_value'], 50)-data['Bid4_value']
        X['MA50_bid5']=MA(data['Bid5_value'], 50)-data['Bid5_value']
        X['MA100_ask1']=MA(data['Ask1_value'], 100)-data['Ask1_value']
        X['MA100_ask2']=MA(data['Ask2_value'], 100)-data['Ask2_value']
        X['MA100_ask3']=MA(data['Ask3_value'], 100)-data['Ask3_value']
        X['MA100_ask4']=MA(data['Ask4_value'], 100)-data['Ask4_value']
        X['MA100_ask5']=MA(data['Ask5_value'], 100)-data['Ask5_value']
        X['MA100_bid1']=MA(data['Bid1_value'], 100)-data['Bid1_value']
        X['MA100_bid2']=MA(data['Bid2_value'], 100)-data['Bid2_value']
        X['MA100_bid3']=MA(data['Bid3_value'], 100)-data['Bid3_value']
        X['MA100_bid4']=MA(data['Bid4_value'], 100)-data['Bid4_value']
        X['MA100_bid5']=MA(data['Bid5_value'], 100)-data['Bid5_value']
        X['MA10_ab1']=MA(data['Ask1_value'], 10) - MA(data['Bid1_value'], 10)
        X['MA10_ab2']=MA(data['Ask2_value'], 10) - MA(data['Bid2_value'], 10)
        X['MA10_ab3']=MA(data['Ask3_value'], 10) - MA(data['Bid3_value'], 10)
        X['MA10_ab4']=MA(data['Ask4_value'], 10) - MA(data['Bid4_value'], 10)
        X['MA10_ab5']=MA(data['Ask5_value'], 10) - MA(data['Bid5_value'], 10)
        X['MA20_ab1']=MA(data['Ask1_value'], 20) - MA(data['Bid1_value'], 20)
        X['MA20_ab2']=MA(data['Ask2_value'], 20) - MA(data['Bid2_value'], 20)
        X['MA20_ab3']=MA(data['Ask3_value'], 20) - MA(data['Bid3_value'], 20)
        X['MA20_ab4']=MA(data['Ask4_value'], 20) - MA(data['Bid4_value'], 20)
        X['MA20_ab5']=MA(data['Ask5_value'], 20) - MA(data['Bid5_value'], 20)
        X['MA30_ab1']=MA(data['Ask1_value'], 30) - MA(data['Bid1_value'], 30)
        X['MA30_ab2']=MA(data['Ask2_value'], 30) - MA(data['Bid2_value'], 30)
        X['MA30_ab3']=MA(data['Ask3_value'], 30) - MA(data['Bid3_value'], 30)
        X['MA30_ab4']=MA(data['Ask4_value'], 30) - MA(data['Bid4_value'], 30)
        X['MA30_ab5']=MA(data['Ask5_value'], 30) - MA(data['Bid5_value'], 30)
        X['MA50_ab1']=MA(data['Ask1_value'], 50) - MA(data['Bid1_value'], 50)
        X['MA50_ab2']=MA(data['Ask2_value'], 50) - MA(data['Bid2_value'], 50)
        X['MA50_ab3']=MA(data['Ask3_value'], 50) - MA(data['Bid3_value'], 50)
        X['MA50_ab4']=MA(data['Ask4_value'], 50) - MA(data['Bid4_value'], 50)
        X['MA50_ab5']=MA(data['Ask5_value'], 50) - MA(data['Bid5_value'], 50)
        X['MA100_ab1']=MA(data['Ask1_value'], 100) - MA(data['Bid1_value'], 100)
        X['MA100_ab2']=MA(data['Ask2_value'], 100) - MA(data['Bid2_value'], 100)
        X['MA100_ab3']=MA(data['Ask3_value'], 100) - MA(data['Bid3_value'], 100)
        X['MA100_ab4']=MA(data['Ask4_value'], 100) - MA(data['Bid4_value'], 100)
        X['MA100_ab5']=MA(data['Ask5_value'], 100) - MA(data['Bid5_value'], 100)
    #布林通道
    if bb == True:
        X = pd.concat([X, BBANDS(data[['mid1']], 100, 5, 10)], axis = 1)
    #均價線
    if avl == True:
        X = pd.concat([X, AVL(data)], axis = 1)
    #MACD
    if macd == True:
        X = pd.concat([X, MACD(data, 12, 26, C_price_name='mid1')], axis = 1)
    #spread of price
    if spread == True:
        X['spread1'] = data['Ask1'] - data['Bid1']
        X['spread2'] = data['Ask2'] - data['Bid2']
        X['spread3'] = data['Ask3'] - data['Bid3']
        X['spread4'] = data['Ask4'] - data['Bid4']
        X['spread5'] = data['Ask5'] - data['Bid5']
    #pct change of value
    #if spread_pct_pq == True:
    #    X['spread1_pct_pq'] = (data['Ask1_value'] / data['Bid1_value']) -1
    #    X['spread2_pct_pq'] = (data['Ask2_value'] / data['Bid2_value']) -1
    #    X['spread3_pct_pq'] = (data['Ask3_value'] / data['Bid3_value']) -1
    #    X['spread4_pct_pq'] = (data['Ask4_value'] / data['Bid4_value']) -1
    #    X['spread5_pct_pq'] = (data['Ask5_value'] / data['Bid5_value']) -1
    #spread of value
    if spread_pq == True:
        X['spread1_pq'] = data['Ask1_value'] - data['Bid1_value']
        X['spread2_pq'] = data['Ask2_value'] - data['Bid2_value'] 
        X['spread3_pq'] = data['Ask3_value'] - data['Bid3_value'] 
        X['spread4_pq'] = data['Ask4_value'] - data['Bid4_value'] 
        X['spread5_pq'] = data['Ask5_value'] - data['Bid5_value'] 
    #price diff
    if price_diff == True:
        X['a51_diff'] = data['Ask5'] - data['Ask1']
        X['b15_diff'] = data['Bid1'] - data['Bid5']
        X['a21_diff_abs'] = np.abs(data['Ask2'] - data['Ask1'])
        X['a32_diff_abs'] = np.abs(data['Ask3'] - data['Ask2'])
        X['a43_diff_abs'] = np.abs(data['Ask4'] - data['Ask3'])
        X['a54_diff_abs'] = np.abs(data['Ask5'] - data['Ask4'])
        X['b21_diff_abs'] = np.abs(data['Bid2'] - data['Bid1'])
        X['b32_diff_abs'] = np.abs(data['Bid3'] - data['Bid2'])
        X['b43_diff_abs'] = np.abs(data['Bid4'] - data['Bid3'])
        X['b54_diff_abs'] = np.abs(data['Bid5'] - data['Bid4'])
    #value diff
    if price_diff_pq == True:
        X['a51_diff_pq'] = data['Ask5_value'] - data['Ask1_value']
        X['b15_diff_pq'] = data['Bid1_value'] - data['Bid5_value']
        X['a21_diff_pq'] = data['Ask2_value'] - data['Ask1_value']
        X['a32_diff_pq'] = data['Ask3_value'] - data['Ask2_value']
        X['a43_diff_pq'] = data['Ask4_value'] - data['Ask3_value']
        X['a54_diff_pq'] = data['Ask5_value'] - data['Ask4_value']
        X['b21_diff_pq'] = data['Bid2_value'] - data['Bid1_value']
        X['b32_diff_pq'] = data['Bid3_value'] - data['Bid2_value']
        X['b43_diff_pq'] = data['Bid4_value'] - data['Bid3_value']
        X['b54_diff_pq'] = data['Bid5_value'] - data['Bid4_value']
    #price mean
    if price_mean == True:
        X['a_mean'] = (data['Ask1'] +data['Ask2'] +data['Ask3'] +data['Ask4'] +data['Ask5']) / 5
        X['b_mean'] = (data['Bid1'] +data['Bid2'] +data['Bid3'] +data['Bid4'] +data['Bid5']) / 5
    #quantity mean
    if qty_mean == True:
        X['aq_mean'] = (data['AskQty1'] +data['AskQty2'] +data['AskQty3'] +data['AskQty4'] +data['AskQty5']) / 5
        X['bq_mean'] = (data['BidQty1'] +data['BidQty2'] +data['BidQty3'] +data['BidQty4'] +data['BidQty5']) / 5
    #value mean
    if pq_mean == True:
        X['a_pq_mean'] = (data['Ask1_value']+data['Ask2_value']+data['Ask3_value']+data['Ask4_value']+data['Ask5_value'])/5
        X['b_pq_mean'] = (data['Bid1_value']+data['Bid2_value']+data['Bid3_value']+data['Bid4_value']+data['Bid5_value'])/5
    #accumulative difference of price and quantity
    if acc_diff == True:
        X['p_acc_diff'] = (data['Ask1'] - data['Bid1']) +(data['Ask2'] - data['Bid2']) + (data['Ask3'] - data['Bid3']) + (data['Ask4'] - data['Bid4']) + (data['Ask5'] - data['Bid5'])
        X['q_acc_diff'] = (data['AskQty1'] - data['BidQty1']) +(data['AskQty2'] - data['BidQty2']) + (data['AskQty3'] - data['BidQty3']) + (data['AskQty4'] - data['BidQty4']) + (data['AskQty5'] - data['BidQty5'])
    #value accumulative difference
    if acc_diff_pq == True:
        X['p_acc_diff_pq'] = (data['Ask1_value'] - data['Bid1_value']) +(data['Ask2_value'] - data['Bid2_value']) + (data['Ask3_value'] - data['Bid3_value']) + (data['Ask4_value'] - data['Bid4_value']) + (data['Ask5_value'] - data['Bid5_value'])
    ############################################################################################################################
    #要考慮換日的因子
    #shift 1 5 10 (price, quantity, value)
    if dt1p == True:
    #1 tick
        X['da1_dt_1'] = data['Ask1']-data.groupby('Date')['Ask1'].shift(1)
        X['da2_dt_1'] = data['Ask2']-data.groupby('Date')['Ask2'].shift(1)
        X['da3_dt_1'] = data['Ask3']-data.groupby('Date')['Ask3'].shift(1)
        X['da4_dt_1'] = data['Ask4']-data.groupby('Date')['Ask4'].shift(1)
        X['da5_dt_1'] = data['Ask5']-data.groupby('Date')['Ask5'].shift(1)
        X['db1_dt_1'] = data['Bid1']-data.groupby('Date')['Bid1'].shift(1)
        X['db2_dt_1'] = data['Bid2']-data.groupby('Date')['Bid2'].shift(1)
        X['db3_dt_1'] = data['Bid3']-data.groupby('Date')['Bid3'].shift(1)
        X['db4_dt_1'] = data['Bid4']-data.groupby('Date')['Bid4'].shift(1)
        X['db5_dt_1'] = data['Bid5']-data.groupby('Date')['Bid5'].shift(1)
        #fillna to 0
        X[['da1_dt_1','da2_dt_1','da3_dt_1','da4_dt_1','da5_dt_1','db1_dt_1','db2_dt_1','db3_dt_1','db4_dt_1','db5_dt_1']] = X[['da1_dt_1','da2_dt_1','da3_dt_1','da4_dt_1','da5_dt_1','db1_dt_1','db2_dt_1','db3_dt_1','db4_dt_1','db5_dt_1']].fillna(value = 0)
        
    if dt1_pq == True:
    #1 tick
        X['da1_dt_1_pq'] = data['Ask1_value']-data.groupby('Date')['Ask1_value'].shift(1)
        X['da2_dt_1_pq'] = data['Ask2_value']-data.groupby('Date')['Ask2_value'].shift(1)
        X['da3_dt_1_pq'] = data['Ask3_value']-data.groupby('Date')['Ask3_value'].shift(1)
        X['da4_dt_1_pq'] = data['Ask4_value']-data.groupby('Date')['Ask4_value'].shift(1)
        X['da5_dt_1_pq'] = data['Ask5_value']-data.groupby('Date')['Ask5_value'].shift(1)
        X['db1_dt_1_pq'] = data['Bid1_value']-data.groupby('Date')['Bid1_value'].shift(1)
        X['db2_dt_1_pq'] = data['Bid2_value']-data.groupby('Date')['Bid2_value'].shift(1)
        X['db3_dt_1_pq'] = data['Bid3_value']-data.groupby('Date')['Bid3_value'].shift(1)
        X['db4_dt_1_pq'] = data['Bid4_value']-data.groupby('Date')['Bid4_value'].shift(1)
        X['db5_dt_1_pq'] = data['Bid5_value']-data.groupby('Date')['Bid5_value'].shift(1)
    if dt5p == True:
    #5 ticks
        X['da1_dt_5'] = data['Ask1']-data.groupby('Date')['Ask1'].shift(5)
        X['da2_dt_5'] = data['Ask2']-data.groupby('Date')['Ask2'].shift(5)
        X['da3_dt_5'] = data['Ask3']-data.groupby('Date')['Ask3'].shift(5)
        X['da4_dt_5'] = data['Ask4']-data.groupby('Date')['Ask4'].shift(5)
        X['da5_dt_5'] = data['Ask5']-data.groupby('Date')['Ask5'].shift(5)
        X['db1_dt_5'] = data['Bid1']-data.groupby('Date')['Bid1'].shift(5)
        X['db2_dt_5'] = data['Bid2']-data.groupby('Date')['Bid2'].shift(5)
        X['db3_dt_5'] = data['Bid3']-data.groupby('Date')['Bid3'].shift(5)
        X['db4_dt_5'] = data['Bid4']-data.groupby('Date')['Bid4'].shift(5)
        X['db5_dt_5'] = data['Bid5']-data.groupby('Date')['Bid5'].shift(5)
        #fill na to 0
        X[['da1_dt_5','da2_dt_5','da3_dt_5','da4_dt_5','da5_dt_5','db1_dt_5','db2_dt_5','db3_dt_5','db4_dt_5','db5_dt_5']] = X[['da1_dt_5','da2_dt_5','da3_dt_5','da4_dt_5','da5_dt_5','db1_dt_5','db2_dt_5','db3_dt_5','db4_dt_5','db5_dt_5']].fillna(value = 0)
    if dt5_pq == True:
    #5 tick
        X['da1_dt_5_pq'] = data['Ask1_value']-data.groupby('Date')['Ask1_value'].shift(5)
        X['da2_dt_5_pq'] = data['Ask2_value']-data.groupby('Date')['Ask2_value'].shift(5)
        X['da3_dt_5_pq'] = data['Ask3_value']-data.groupby('Date')['Ask3_value'].shift(5)
        X['da4_dt_5_pq'] = data['Ask4_value']-data.groupby('Date')['Ask4_value'].shift(5)
        X['da5_dt_5_pq'] = data['Ask5_value']-data.groupby('Date')['Ask5_value'].shift(5)
        X['db1_dt_5_pq'] = data['Bid1_value']-data.groupby('Date')['Bid1_value'].shift(5)
        X['db2_dt_5_pq'] = data['Bid2_value']-data.groupby('Date')['Bid2_value'].shift(5)
        X['db3_dt_5_pq'] = data['Bid3_value']-data.groupby('Date')['Bid3_value'].shift(5)
        X['db4_dt_5_pq'] = data['Bid4_value']-data.groupby('Date')['Bid4_value'].shift(5)
        X['db5_dt_5_pq'] = data['Bid5_value']-data.groupby('Date')['Bid5_value'].shift(5)                                            
    if dt10p == True:
    #10 ticks
        X['da1_dt_10'] = data['Ask1']-data.groupby('Date')['Ask1'].shift(10)
        X['da2_dt_10'] = data['Ask2']-data.groupby('Date')['Ask2'].shift(10)
        X['da3_dt_10'] = data['Ask3']-data.groupby('Date')['Ask3'].shift(10)
        X['da4_dt_10'] = data['Ask4']-data.groupby('Date')['Ask4'].shift(10)
        X['da5_dt_10'] = data['Ask5']-data.groupby('Date')['Ask5'].shift(10)
        X['db1_dt_10'] = data['Bid1']-data.groupby('Date')['Bid1'].shift(10)
        X['db2_dt_10'] = data['Bid2']-data.groupby('Date')['Bid2'].shift(10)
        X['db3_dt_10'] = data['Bid3']-data.groupby('Date')['Bid3'].shift(10)
        X['db4_dt_10'] = data['Bid4']-data.groupby('Date')['Bid4'].shift(10)
        X['db5_dt_10'] = data['Bid5']-data.groupby('Date')['Bid5'].shift(10)
        #fill na to 0
        X[['da1_dt_10','da2_dt_10','da3_dt_10','da4_dt_10','da5_dt_10','db1_dt_10','db2_dt_10','db3_dt_10','db4_dt_10','db5_dt_10']] = X[['da1_dt_10','da2_dt_10','da3_dt_10','da4_dt_10','da5_dt_10','db1_dt_10','db2_dt_10','db3_dt_10','db4_dt_10','db5_dt_10']].fillna(value = 0)
    if dt10_pq == True:
    #10 tick
        X['da1_dt_10_pq'] = data['Ask1_value']-data.groupby('Date')['Ask1_value'].shift(10)
        X['da2_dt_10_pq'] = data['Ask2_value']-data.groupby('Date')['Ask2_value'].shift(10)
        X['da3_dt_10_pq'] = data['Ask3_value']-data.groupby('Date')['Ask3_value'].shift(10)
        X['da4_dt_10_pq'] = data['Ask4_value']-data.groupby('Date')['Ask4_value'].shift(10)
        X['da5_dt_10_pq'] = data['Ask5_value']-data.groupby('Date')['Ask5_value'].shift(10)
        X['db1_dt_10_pq'] = data['Bid1_value']-data.groupby('Date')['Bid1_value'].shift(10)
        X['db2_dt_10_pq'] = data['Bid2_value']-data.groupby('Date')['Bid2_value'].shift(10)
        X['db3_dt_10_pq'] = data['Bid3_value']-data.groupby('Date')['Bid3_value'].shift(10)
        X['db4_dt_10_pq'] = data['Bid4_value']-data.groupby('Date')['Bid4_value'].shift(10)
        X['db5_dt_10_pq'] = data['Bid5_value']-data.groupby('Date')['Bid5_value'].shift(10)                                           
    #quantity
    if dt1q == True:
    #1 tick
        X['daq1_dt_1'] = data['AskQty1']-data.groupby('Date')['AskQty1'].shift(1)
        X['daq2_dt_1'] = data['AskQty2']-data.groupby('Date')['AskQty2'].shift(1)
        X['daq3_dt_1'] = data['AskQty3']-data.groupby('Date')['AskQty3'].shift(1)
        X['daq4_dt_1'] = data['AskQty4']-data.groupby('Date')['AskQty4'].shift(1)
        X['daq5_dt_1'] = data['AskQty5']-data.groupby('Date')['AskQty5'].shift(1)
        X['dbq1_dt_1'] = data['BidQty1']-data.groupby('Date')['BidQty1'].shift(1)
        X['dbq2_dt_1'] = data['BidQty2']-data.groupby('Date')['BidQty2'].shift(1)
        X['dbq3_dt_1'] = data['BidQty3']-data.groupby('Date')['BidQty3'].shift(1)
        X['dbq4_dt_1'] = data['BidQty4']-data.groupby('Date')['BidQty4'].shift(1)
        X['dbq5_dt_1'] = data['BidQty5']-data.groupby('Date')['BidQty5'].shift(1)
        #fill na to 0
        X[['daq1_dt_1','daq2_dt_1','daq3_dt_1','daq4_dt_1','daq5_dt_1','dbq1_dt_1','dbq2_dt_1','dbq3_dt_1','dbq4_dt_1','dbq5_dt_1']] = X[['daq1_dt_1','daq2_dt_1','daq3_dt_1','daq4_dt_1','daq5_dt_1','dbq1_dt_1','dbq2_dt_1','dbq3_dt_1','dbq4_dt_1','dbq5_dt_1']].fillna(value = 0)
    if dt5q == True:
    #5 ticks
        X['daq1_dt_5'] = data['AskQty1']-data.groupby('Date')['AskQty1'].shift(5)
        X['daq2_dt_5'] = data['AskQty2']-data.groupby('Date')['AskQty2'].shift(5)
        X['daq3_dt_5'] = data['AskQty3']-data.groupby('Date')['AskQty3'].shift(5)
        X['daq4_dt_5'] = data['AskQty4']-data.groupby('Date')['AskQty4'].shift(5)
        X['daq5_dt_5'] = data['AskQty5']-data.groupby('Date')['AskQty5'].shift(5)
        X['dbq1_dt_5'] = data['BidQty1']-data.groupby('Date')['BidQty1'].shift(5)
        X['dbq2_dt_5'] = data['BidQty2']-data.groupby('Date')['BidQty2'].shift(5)
        X['dbq3_dt_5'] = data['BidQty3']-data.groupby('Date')['BidQty3'].shift(5)
        X['dbq4_dt_5'] = data['BidQty4']-data.groupby('Date')['BidQty4'].shift(5)
        X['dbq5_dt_5'] = data['BidQty5']-data.groupby('Date')['BidQty5'].shift(5)
        #fill na to 0
        X[['daq1_dt_5','daq2_dt_5','daq3_dt_5','daq4_dt_5','daq5_dt_5','dbq1_dt_5','dbq2_dt_5','dbq3_dt_5','dbq4_dt_5','dbq5_dt_5']] = X[['daq1_dt_5','daq2_dt_5','daq3_dt_5','daq4_dt_5','daq5_dt_5','dbq1_dt_5','dbq2_dt_5','dbq3_dt_5','dbq4_dt_5','dbq5_dt_5']].fillna(value = 0)
    if dt10q == True:
    #10 ticks
        X['daq1_dt_10'] = data['AskQty1']-data.groupby('Date')['AskQty1'].shift(10)
        X['daq2_dt_10'] = data['AskQty2']-data.groupby('Date')['AskQty2'].shift(10)
        X['daq3_dt_10'] = data['AskQty3']-data.groupby('Date')['AskQty3'].shift(10)
        X['daq4_dt_10'] = data['AskQty4']-data.groupby('Date')['AskQty4'].shift(10)
        X['daq5_dt_10'] = data['AskQty5']-data.groupby('Date')['AskQty5'].shift(10)
        X['dbq1_dt_10'] = data['BidQty1']-data.groupby('Date')['BidQty1'].shift(10)
        X['dbq2_dt_10'] = data['BidQty2']-data.groupby('Date')['BidQty2'].shift(10)
        X['dbq3_dt_10'] = data['BidQty3']-data.groupby('Date')['BidQty3'].shift(10)
        X['dbq4_dt_10'] = data['BidQty4']-data.groupby('Date')['BidQty4'].shift(10)
        X['dbq5_dt_10'] = data['BidQty5']-data.groupby('Date')['BidQty5'].shift(10)
        #fill na to 0
        X[['daq1_dt_10','daq2_dt_10','daq3_dt_10','daq4_dt_10','daq5_dt_10','dbq1_dt_10','dbq2_dt_10','dbq3_dt_10','dbq4_dt_10','dbq5_dt_10']] = X[['daq1_dt_10','daq2_dt_10','daq3_dt_10','daq4_dt_10','daq5_dt_10','dbq1_dt_10','dbq2_dt_10','dbq3_dt_10','dbq4_dt_10','dbq5_dt_10']].fillna(value = 0)    
    #features crosses
    #dt1
    if (cross1 == True) and (dt1p == True) and (dt1q == True):
        #ask
        X['aq1dt1_cross'] = X['da1_dt_1'] * X['daq1_dt_1']
        X['aq2dt1_cross'] = X['da2_dt_1'] * X['daq2_dt_1']
        X['aq3dt1_cross'] = X['da3_dt_1'] * X['daq3_dt_1']
        X['aq4dt1_cross'] = X['da4_dt_1'] * X['daq4_dt_1']
        X['aq5dt1_cross'] = X['da5_dt_1'] * X['daq5_dt_1']
        #bid
        X['bq1dt1_cross'] = X['db1_dt_1'] * X['dbq1_dt_1']
        X['bq2dt1_cross'] = X['db2_dt_1'] * X['dbq2_dt_1']
        X['bq3dt1_cross'] = X['db3_dt_1'] * X['dbq3_dt_1']
        X['bq4dt1_cross'] = X['db4_dt_1'] * X['dbq4_dt_1']
        X['bq5dt1_cross'] = X['db5_dt_1'] * X['dbq5_dt_1']
    #dt5
    if (cross5 == True) and (dt5p == True) and (dt5q == True):
        #ask
        X['aq1dt5_cross'] = X['da1_dt_5'] * X['daq1_dt_5']
        X['aq2dt5_cross'] = X['da2_dt_5'] * X['daq2_dt_5']
        X['aq3dt5_cross'] = X['da3_dt_5'] * X['daq3_dt_5']
        X['aq4dt5_cross'] = X['da4_dt_5'] * X['daq4_dt_5']
        X['aq5dt5_cross'] = X['da5_dt_5'] * X['daq5_dt_5']
        #bid
        X['bq1dt5_cross'] = X['db1_dt_5'] * X['dbq1_dt_5']
        X['bq2dt5_cross'] = X['db2_dt_5'] * X['dbq2_dt_5']
        X['bq3dt5_cross'] = X['db3_dt_5'] * X['dbq3_dt_5']
        X['bq4dt5_cross'] = X['db4_dt_5'] * X['dbq4_dt_5']
        X['bq5dt5_cross'] = X['db5_dt_5'] * X['dbq5_dt_5']
    #dt10
    if (cross10 == True) and (dt10p == True) and (dt10q == True):
        #ask
        X['aq1dt10_cross'] = X['da1_dt_10'] * X['daq1_dt_10']
        X['aq2dt10_cross'] = X['da2_dt_10'] * X['daq2_dt_10']
        X['aq3dt10_cross'] = X['da3_dt_10'] * X['daq3_dt_10']
        X['aq4dt10_cross'] = X['da4_dt_10'] * X['daq4_dt_10']
        X['aq5dt10_cross'] = X['da5_dt_10'] * X['daq5_dt_10']
        #bid
        X['bq1dt10_cross'] = X['db1_dt_10'] * X['dbq1_dt_10']
        X['bq2dt10_cross'] = X['db2_dt_10'] * X['dbq2_dt_10']
        X['bq3dt10_cross'] = X['db3_dt_10'] * X['dbq3_dt_10']
        X['bq4dt10_cross'] = X['db4_dt_10'] * X['dbq4_dt_10']
        X['bq5dt10_cross'] = X['db5_dt_10'] * X['dbq5_dt_10']
    df = pd.concat([data, X], axis = 1)
    df = df.dropna()
    df = df.reset_index(drop = True)
    X = X.dropna()
    X = X.reset_index(drop = True)
    return X, df

#normalize
def normalize(df):
    norm = df.apply(lambda x: x / (np.std(x)))
    return norm

#scale back to the true range
def true_range(df, x, response):
    X = x * np.std(df[response])
    return X

#rolling windows to build sequential data
#ten ticks predict next 10 seconds
def train_windows(df, response, ref_day=10, predict_day=1):
    X_train, Y_train = [], []
    for i in range(df.shape[0]-predict_day-ref_day+1):
        #扣掉response
        #記得最後一行要放response
        X_train.append(np.array(df.iloc[i:i+ref_day,:-1]))
        Y_train.append(np.array(df.iloc[i+ref_day-1:i+ref_day][response]))
    return np.array(X_train), np.array(Y_train)

#LSTM (when add the drop out layer in order to deal with overfitting)
def lstm_stock_model(shape):
    model = Sequential()
    #return sequence = True -> means the network will have long memory
    #first layer
    model.add(LSTM(256, input_shape=(shape[1], shape[2]), return_sequences=True))
    #first drop out layer(drop 50% of the previous one to avoid over-fitting)
    model.add(Dropout(0.5))
    #second layer
    model.add(LSTM(256, return_sequences=True))
    #second drop out layer
    model.add(Dropout(0.5))
    #add dense in every time step, dimension -> 1
    model.add(TimeDistributed(Dense(1)))
    #third drop out layer
    model.add(Dropout(0.5))
    #flatten: 多維 -> 一維
    model.add(Flatten())
    #forth drop out layer
    #model.add(Dropout(0.5))
    #dense layer
    model.add(Dense(10,activation='linear'))
    #1 -> output dimension
    model.add(Dense(1,activation='linear'))
    #change learning rate 0.001 -> 0.0005
    adam = keras.optimizers.Adam(lr=0.0005, beta_1=0.9, beta_2=0.999, decay=0.0, amsgrad=False)
    model.compile(loss="mean_squared_error", optimizer=adam,metrics=['mean_squared_error'])
    #using MSE
    #model.compile(loss="mean_squared_error", optimizer="adam",metrics=['mean_squared_error'])
    model.summary()
    return model

#model performance
def model_performance(y, f):
    tot = np.sum(np.square(y - np.mean(y)))
    res = np.sum(np.square(y - f))
    r_squared = 1 - res / tot
    mse = np.mean(np.square(y - f)) * (1 / len(y))
    print('MSE:', mse)
    print('r-squared:', r_squared)
    return r_squared

#10 sec Y
def y_in_sec(data_train1, sec=10):
    data_train1['sec_plus'] = data_train1['sec'] + sec
    date_list = data_train1['Date'].unique()
    Y = pd.DataFrame()
    for i in date_list:
        df = data_train1[data_train1.Date == i]
        df = df.reset_index(drop = True)
        y = pd.DataFrame(data=np.zeros(len(df)))
        for j in range(len(df)):
            if len(df['sec'][df['sec'] > df['sec_plus'][j]].index) == 0:
                y.iloc[j:len(df)] = (df['mid1'][len(df) - 1] / df['mid1'][j]) - 1
                break
            else:
                idx = df['sec'][df['sec'] > df['sec_plus'][j]].index[0]
                y.iloc[j] = (df['mid1'][idx] / df['mid1'][j]) - 1
        Y = pd.concat([Y, y], axis = 0)
    return Y

data_train['Date'] = pd.to_datetime(data_train['TxTime'])
data_train['Date'] = [str(x)[0:10] for x in data_train['Date']]
data_test['Date'] = pd.to_datetime(data_test['TxTime'])
data_test['Date'] = [str(x)[0:10] for x in data_test['Date']]

from datetime import datetime
import time
data_train['Time'] = pd.to_datetime(data_train['TxTime'])
data_train['Time'] = [str(x)[11:19] for x in data_train['Time']]
data_train['sec'] = np.zeros(len(data_train))
for i in range(len(data_train)):
    data_train['sec'].iloc[i] = int(data_train['Time'][i][0:2]) * 3600 + int(data_train['Time'][i][3:5]) * 60 + int(data_train['Time'][i][6:8])

X_in, data_train1 = AlphaGenerate_Tick(data_train,ma=True,macd=True,
                                      spread_pq=True,price_diff_pq=True,
                                      dt5_pq=True,dt10_pq=True,bb=True,
                                      dt5q=True,dt10q=True,dt5p=True,dt10p=True)

#這是我寫抓10秒後的return的function，跑太久了，可以改用其他方法抓(rolling date)
Y_train = y_in_sec(data_train1, sec=10)

data_test['Time'] = pd.to_datetime(data_test['TxTime'])
data_test['Time'] = [str(x)[11:19] for x in data_test['Time']]
data_test['sec'] = np.zeros(len(data_test))
for i in range(len(data_test)):
    data_test['sec'].iloc[i] = int(data_test['Time'][i][0:2]) * 3600 + int(data_test['Time'][i][3:5]) * 60 + int(data_test['Time'][i][6:8])

#test set
X_out, data_test1 = AlphaGenerate_Tick(data_test,ma=True,macd=True,
                                      spread_pq=True,price_diff_pq=True,
                                      dt5_pq=True,dt10_pq=True,bb=True,
                                      dt5q=True,dt10q=True,dt5p=True,dt10p=True)

Y_test = y_in_sec(data_test1, sec=10)

#10秒算一次return(y)
X_in['return_10s'] = Y_train.values
X_in_normal = normalize(X_in)
X_out['return_10s'] = Y_test.values
X_out_normal = normalize(X_out)

#adjust the parameters in lstm
batch_size = [128, 256, 512]
validation_split = [0.1, 0.2, 0.3]
#build sequential data set
#lstm的特點: sequential data
X_train, Y_train = train_windows(X_in_normal, 'return_10s', 10, 1)
X_test, Y_test = train_windows(X_out_normal, 'return_10s', 10, 1)

#adding drop out layer(pct = 0.5)
#batch size = 128
#validation split = 0.3 (not letting val loss < loss)
#early stop -> val loss patience = 10 
#3 drop out layer
#y用秒來分 (10秒)
model_1 = lstm_stock_model(X_train.shape)
#callback = EarlyStopping(monitor="val_mean_squared_error", patience=10, verbose=1, mode="min")
history_1 = model_1.fit(X_train, Y_train, epochs=3, batch_size=batch_size[0], validation_split=validation_split[2], shuffle=True)#, callbacks=[callback], shuffle=True)

X_t1 = model_1.predict(X_train)
Xt1 = model_1.predict(X_test)
X_t1 = X_t1.reshape(1, len(X_t1))[0]
Xt1 = Xt1.reshape(1, len(Xt1))[0]
X_t1 = true_range(X_in, X_t1, 'return_10s')
Xt1 = true_range(X_out, Xt1, 'return_10s')

print('train set')
model_performance(X_in['return_10s'].iloc[10:].values, X_t1)
print('test set')
model_performance(X_out['return_10s'].iloc[10:].values, Xt1)

plt.scatter(X_in['return_10s'].iloc[10:].values, X_t1, s=30, c='red', alpha=.3)
plt.title('In Sample')
plt.ylim(-0.01, 0.01)
plt.xlim(-0.01, 0.01)
x = [-0.01, 0.01]
plt.plot(x, x, 'k--')

bins = np.linspace(-0.006, 0.006, 20)
plt.hist(X_t1, bins, alpha=0.5, label='y_pred')
plt.hist(X_in['return_10s'].iloc[10:].values, bins, alpha=0.5, label='y')
plt.legend(loc='upper right')
plt.title('Predicted Return (train)')

plt.scatter(X_out['return_10s'].iloc[10:].values, Xt1, s=30, c='red', alpha=.3)
plt.title('Out Sample')
plt.ylim(-0.01, 0.01)
plt.xlim(-0.01, 0.01)
x = [-0.01, 0.01]
plt.plot(x, x, 'k--')

bins = np.linspace(-0.006, 0.006, 20)
plt.hist(Xt1, bins, alpha=0.5, label='y_pred')
plt.hist(X_out['return_10s'].iloc[10:].values, bins, alpha=0.5, label='y')
plt.legend(loc='upper right')
plt.title('Predicted Return (test)')